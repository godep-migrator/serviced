// Copyright 2014, The Serviced Authors. All rights reserved.
// Use of this source code is governed by a
// license that can be found in the LICENSE file.

// Package serviced - agent implements a service that runs on a serviced node.
// It is responsible for ensuring that a particular node is running the correct
// services and reporting the state and health of those services back to the
// master serviced.
package serviced

import (
	"github.com/zenoss/glog"
	"github.com/zenoss/serviced/commons"
	coordclient "github.com/zenoss/serviced/coordinator/client"
	coordzk "github.com/zenoss/serviced/coordinator/client/zookeeper"
	"github.com/zenoss/serviced/dao"
	"github.com/zenoss/serviced/datastore"
	"github.com/zenoss/serviced/domain"
	"github.com/zenoss/serviced/domain/pool"
	"github.com/zenoss/serviced/domain/service"
	"github.com/zenoss/serviced/domain/servicestate"
	"github.com/zenoss/serviced/domain/user"
	"github.com/zenoss/serviced/facade"
	"github.com/zenoss/serviced/proxy"
	"github.com/zenoss/serviced/utils"
	"github.com/zenoss/serviced/volume"
	zkDocker "github.com/zenoss/serviced/zzk/docker"
	zkService "github.com/zenoss/serviced/zzk/service"
	zkVirtualIP "github.com/zenoss/serviced/zzk/virtualips"

	docker "github.com/zenoss/go-dockerclient"

	"encoding/json"
	"errors"
	"fmt"
	"io"
	"io/ioutil"
	"os"
	"os/exec"
	"path"
	"path/filepath"
	"strconv"
	"strings"
	"syscall"
	"time"
)

/*
 glog levels:
 0: important info that should always be shown
 1: info that might be important for debugging
 2: very verbose debug info
 3: trace level info
*/

const (
	dockerEndpoint     = "unix:///var/run/docker.sock"
	circularBufferSize = 1000
)

// HostAgent is an instance of the control plane Agent.
type HostAgent struct {
	master          string               // the connection string to the master agent
	uiport          string               // the port to the ui (legacy was port 8787, now default 443)
	hostID          string               // the hostID of the current host
	dockerDNS       []string             // docker dns addresses
	varPath         string               // directory to store serviced	 data
	mount           []string             // each element is in the form: dockerImage,hostPath,containerPath
	vfs             string               // driver for container volumes
	currentServices map[string]*exec.Cmd // the current running services
	mux             *proxy.TCPMux
	closing         chan chan error
	proxyRegistry   proxy.ProxyRegistry
	zkClient        *coordclient.Client
	dockerRegistry  string // the docker registry to use
	facade          *facade.Facade
	context         datastore.Context
}

// assert that this implemenents the Agent interface

func getZkDSN(zookeepers []string) string {
	if len(zookeepers) == 0 {
		zookeepers = []string{"127.0.0.1:2181"}
	}
	dsn := coordzk.DSN{
		Servers: zookeepers,
		Timeout: time.Second * 15,
	}
	return dsn.String()
}

// NewHostAgent creates a new HostAgent given a connection string
func NewHostAgent(master string, uiport string, dockerDNS []string, varPath string, mount []string, vfs string, zookeepers []string, mux *proxy.TCPMux, dockerRegistry string) (*HostAgent, error) {
	// save off the arguments
	agent := &HostAgent{}
	agent.dockerRegistry = dockerRegistry
	agent.master = master
	agent.uiport = uiport
	agent.dockerDNS = dockerDNS
	agent.varPath = varPath
	agent.mount = mount
	agent.vfs = vfs
	agent.mux = mux

	dsn := getZkDSN(zookeepers)
	basePath := ""
	zkClient, err := coordclient.New("zookeeper", dsn, basePath, nil)
	if err != nil {
		return nil, err
	}
	agent.zkClient = zkClient

	agent.closing = make(chan chan error)
	hostID, err := utils.HostID()
	if err != nil {
		panic("Could not get hostid")
	}
	agent.hostID = hostID
	agent.currentServices = make(map[string]*exec.Cmd)

	agent.proxyRegistry = proxy.NewDefaultProxyRegistry()
	go agent.start()
	return agent, err

	/* FIXME: this should work here

	addr, err := net.ResolveTCPAddr("tcp", processForwarderAddr)
	if err != nil {
		return nil, err
	}
	listener, err := net.ListenTCP("tcp", addr)
	if err != nil {
		return nil, err
	}

	sio := shell.NewProcessForwarderServer(proxyOptions.servicedEndpoint)
	sio.Handle("/", http.FileServer(http.Dir("/serviced/www/")))
	go http.Serve(listener, sio)
	c := &ControllerP{
		processForwarderListener: listener,
	}
	*/

}

// Use the Context field of the given template to fill in all the templates in
// the Command fields of the template's ServiceDefinitions
func injectContext(s *service.Service, cp dao.ControlPlane) error {

	getSvc := func(svcID string) (service.Service, error) {
		svc := service.Service{}
		err := cp.GetService(svcID, &svc)
		return svc, err
	}
	return s.Evaluate(getSvc)
}

// Shutdown stops the agent
func (a *HostAgent) Shutdown() error {
	glog.V(2).Info("Issuing shutdown signal")
	errc := make(chan error)
	a.closing <- errc
	glog.Info("exiting shutdown")
	return <-errc
}

// AttachService attempts to attach to a running container
func (a *HostAgent) AttachService(done chan<- interface{}, svc *service.Service, state *servicestate.ServiceState) error {
	container, err := getDockerState(state.DockerID)
	if err != nil {
		return err
	}

	glog.V(2).Infof("Agent.updateCurrentState got container state for docker ID %s: %v", serviceState.DockerID, containerState)
	if !container.State.Running {
		return fmt.Errorf("container not running for %s", state.Id)
	}

	dc, err := docker.NewClient(dockerEndpoint)
	if err != nil {
		glog.Error("Could not create docker client: ", err)
		return err
	}

	go a.waitInstance(dc, done, svc, state)
	return true, nil
}

// StopService terminates a particular service instance (serviceState) on the localhost
func (a *HostAgent) StopService(serviceState *servicestate.ServiceState) error {
	return a.dockerTerminate(serviceState.Id)
}

func (a *HostAgent) dockerRemove(dockerID string) error {
	glog.V(1).Infof("Ensuring that container %s does not exist", dockerID)

	dc, err := docker.NewClient(dockerEndpoint)
	if err != nil {
		glog.Errorf("can't create docker client: %v", err)
		return err
	}

	if err = dc.RemoveContainer(docker.RemoveContainerOptions{ID: dockerID, RemoveVolumes: true}); err != nil {
		glog.Errorf("unable to remove container %s: %v", dockerID, err)
		return err
	}

	glog.V(2).Infof("Successfully removed %s", dockerID)
	return nil
}

func (a *HostAgent) dockerTerminate(dockerID string) error {
	glog.V(1).Infof("Killing container %s", dockerID)

	dc, err := docker.NewClient(dockerEndpoint)
	if err != nil {
		glog.Errorf("can't create docker client: %v", err)
		return err
	}

	if err = dc.KillContainer(dockerID); err != nil && !strings.Contains(err.Error(), "No such container") {
		glog.Errorf("unable to kill container %s: %v", dockerID, err)
		return err
	}

	glog.V(2).Infof("Successfully killed %s", dockerID)
	return nil
}

// Get the state of the docker container given the dockerId
func getDockerState(dockerID string) (*docker.Container, error) {
	glog.V(1).Infof("Inspecting container: %s", dockerID)

	dc, err := docker.NewClient(dockerEndpoint)
	if err != nil {
		glog.Errorf("can't create docker client: %v", err)
		return nil, err
	}

	return dc.InspectContainer(dockerID)
}

func dumpOut(stdout, stderr io.Reader, size int) {
	dumpBuffer(stdout, size, "stdout")
	dumpBuffer(stderr, size, "stderr")
}

func dumpBuffer(reader io.Reader, size int, name string) {
	buffer := make([]byte, size)
	if n, err := reader.Read(buffer); err != nil {
		glog.V(1).Infof("Unable to read %s of dump", name)
	} else {
		message := strings.TrimSpace(string(buffer[:n]))
		if len(message) > 0 {
			glog.V(0).Infof("Process %s:\n%s", name, message)
		}
	}
}

func (a *HostAgent) CheckInstance(state *servicestate.ServiceState) error {
	ctr, err := getDockerState(state.Id)
	if err != nil {
		return err
	}

	// Update the service state
	state.DockerID = ctr.ID
	state.Started = ctr.Created
	state.PrivateIP = ctr.NetworkSettings.IPAddress
	state.PortMapping = make(map[string][]domain.HostIPAndPort)
	for k, v := range ctr.NetworkSettings.Ports {
		pm := []domain.HostIPAndPort{}
		for _, pb := range v {
			pm = append(pm, domain.HostIPAndPort{HostIP: pb.HostIp, HostPort: pb.HostPort})
		}
		state.PortMapping[string(k)] = pm
	}

	return nil
}

func (a *HostAgent) waitInstance(dc *docker.Client, done chan<- interface{}, svc *service.Service, state *servicestate.ServiceState) {
	defer close(done)
	exited := make(chan error)
	go func() {
		rc, err := a.docker.WaitContainer(state.DockerID)
		if err != nil || rc != 0 || glog.GetVerbosity() > 0 {
			// TODO: output of docker logs is potentaially very large
			// this should be implemented another way, perhaps a docker attach
			// or extend docker to give the last N seconds
			if output, err := exec.Command("docker", "logs", state.DockerID).CombinedOutput(); err != nil {
				glog.Errorf("Could not get logs for container %s", state.DockerID)
			} else {
				var buffersize = 1000
				if index := len(output) - buffersize; index > 0 {
					output = output[index:]
				}
				glog.Warningf("Last %d bytes of container %s: %s", buffersize, containerID, string(output))
			}
		}
		glog.Infof("docker wait %s exited", containerID)
		exited <- err
		// remove the container
		if err := dc.RemoveContainer(docker.RemoveContainerOptions{ID: containerID, RemoveVolumes: true}); err != nil {
			glog.Errorf("Could not remove container %s: %s", containerID, err)
		}
	}()

	if err := func(interval, retries int) (err error) {
		for i := 0; i < retries; i++ {
			if err = a.CheckInstance(state); err == nil {
				return nil
			}
			<-time.After(interval * time.Second)
		}
		return err
	}(3, 30); err != nil {
		glog.V(2).Infof("Could not get service state for %s: %s", state.Id, err)
		return
	}

	glog.V(4).Infof("Looking for address assignment in service %s (%s)", svc.Name, svc.Id)
	for _, endpoint := range svc.Endpoints {
		if addressconfig := endpoint.GetAssignment; addressconfig != nil {
			glog.V(4).Infof("Found address assignment for service %s (%s) with endpoint %s", svc.Name, svc.Id, endpoint.Name)
			var (
				proxyID  = fmt.Sprintf("%s:%s", state.ServiceID, endpoint.Name)
				frontend = proxy.ProxyAddress{IP: addressconfig.IPAddr, Port: addressconfig.Port}
				backend  = proxy.ProxyAddress{IP: state.PrivateIP, Port: endpoint.PortNumber}
			)
			if err := a.proxyRegistry.CreateProxy(proxyID, endpoint.Protocol, frontend, backend); err != nil {
				glog.Warningf("Could not start external address proxy for %s: %s", proxyID, err)
			}
			defer a.proxyRegistry.RemoveProxy(proxyID)
		}
	}

	status, err := getExitCode(<-exited)
	if err != nil {
		glog.V(1).Info("Unable to determine exit code for %s: %s", state.Id, err)
		return
	}

	switch status {
	case 0:
		glog.V(0).Info("Finished processing instance ", state.Id)
	case 2:
		glog.V(1).Info("Docker process stopped for instance ", state.Id)
	case 137:
		glog.V(1).Info("Docker process killed for instance ", state.Id)
	default:
		glog.V(0).Infof("Docker process exited %s for instance", status, state.Id)
	}
}

func getSubvolume(varPath, poolID, tenantID, fs string) (*volume.Volume, error) {
	baseDir, _ := filepath.Abs(path.Join(varPath, "volumes"))
	if _, err := volume.Mount(fs, poolID, baseDir); err != nil {
		return nil, err
	}
	baseDir, _ = filepath.Abs(path.Join(varPath, "volumes", poolID))
	return volume.Mount(fs, tenantID, baseDir)
}

/*
writeConfFile is responsible for writing contents out to a file
Input string prefix	 : cp_cd67c62b-e462-5137-2cd8-38732db4abd9_zenmodeler_logstash_forwarder_conf_
Input string id		 : Service ID (example cd67c62b-e462-5137-2cd8-38732db4abd9)
Input string filename: zenmodeler_logstash_forwarder_conf
Input string content : the content that you wish to write to a file
Output *os.File	 f	 : file handler to the file that you've just opened and written the content to
Example name of file that is written: /tmp/cp_cd67c62b-e462-5137-2cd8-38732db4abd9_zenmodeler_logstash_forwarder_conf_592084261
*/
func writeConfFile(prefix string, id string, filename string, content string) (*os.File, error) {
	f, err := ioutil.TempFile("", prefix)
	if err != nil {
		glog.Errorf("Could not generate tempfile for config %s %s", id, filename)
		return f, err
	}
	_, err = f.WriteString(content)
	if err != nil {
		glog.Errorf("Could not write out config file %s %s", id, filename)
		return f, err
	}

	return f, nil
}

// chownConfFile() runs 'chown $owner $filename && chmod $permissions $filename'
// using the given dockerImage. An error is returned if owner is not specified,
// the owner is not in user:group format, or if there was a problem setting
// the permissions.
func chownConfFile(filename, owner, permissions string, dockerImage string) error {
	// TODO: reach in to the dockerImage and get the effective UID, GID so we can do this without a bind mount
	if !validOwnerSpec(owner) {
		return fmt.Errorf("unsupported owner specification: %s", owner)
	}

	uid, gid, err := getInternalImageIDs(owner, dockerImage)
	if err != nil {
		return err
	}
	// this will fail if we are not running as root
	if err := os.Chown(filename, uid, gid); err != nil {
		return err
	}
	octal, err := strconv.ParseInt(permissions, 8, 32)
	if err != nil {
		return err
	}
	if err := os.Chmod(filename, os.FileMode(octal)); err != nil {
		return err
	}
	return nil
}

func (a *HostAgent) StartService(done chan<- interface{}, svc *service.Service, state *servicestate.ServiceState) error {
	glog.V(2).Infof("About to start service %s (%s)", svc.Name, svc.Id)
	client, err := NewControlClient(a.master)
	if err != nil {
		glog.Errorf("Could not start ControlPlane client: %s", err)
		return err
	}
	defer client.Close()

	// start from a known good state
	a.dockerTerminate(state.Id)
	a.dockerRemove(state.Id)

	dc, err := docker.NewClient(dockerEndpoint)
	if err != nil {
		glog.Errorf("Cannot create docker client: %s", err)
		return err
	}

	eventmonitor, err := dc.MonitorEvents()
	if err != nil {
		glog.Errorf("Cannot monitor docker events: %s", err)
		return err
	}
	defer eventmonitor.Close()

	// create the docker client config and host config structures necessary to create and start the service
	dockerconfig, hostconfig, err := a.configureContainer(client, done, svc, state)
	if err != nil {
		glog.Errorf("Cannot configure container: %v", err)
		return err
	}

	cjson, _ := json.MarshalIndent(dockerconfig, "", "    ")
	glog.V(3).Info(">>> CreateContainerOptions:\n", string(cjson))
	hcjson, _ := json.MarshalIndent(hostconfig, "", "    ")
	glog.V(2).Info(">>> HostConfigOptions:\n", string(hcjson))

	// pull the image from the registry first if necessary, then attempt to create the container
	registry, err := commons.NewDockerRegistry(a.dockerRegistry)
	if err != nil {
		glog.Errorf("Cannot use docker registry for %s: %s", a.dockerRegistry, err)
		return err
	}

	ctr, err := commons.CreateContainer(registry, dc, docker.CreateContainerOptions{Name: state.Id, Config: dockerconfig})
	if err != nil {
		glog.Errorf("Cannot create container %v: %s", dockerconfig, err)
		return err
	}

	glog.V(2).Infof("Created container %s for service %s (%s): %v", ctr.ID, state.Id, svc.Name, svc.Id, dockerconfig.Cmd)

	// use the docker client EventMonitor to listen to events from this container
	subscription, err := eventmonitor.Subscribe(ctr.ID)
	if err != nil {
		glog.Errorf("Cannot subscribe to Docker events on container %s: %s", ctr.ID, err)
		return err
	}

	evtmonitorChan := make(chan struct{})
	subscription.Handle(docker.Start, func(e docker.Event) error {
		glog.V(2).Infof("Container %s starting instance %s for service %s (%s): %v", e["id"], state.Id, svc.Name, svc.Id, dockerconfig.Cmd)
		emc <- struct{}{}
		return nil
	})

	if err := dc.StartContainer(ctr.ID, hostconfig); err != nil {
		glog.Errorf("Canno start container %s for service %s (%s): %s", ctr.Id, svc.Name, svc.Id, err)
		return err
	}

	// wait until we get notified that the container has started, or 10 seconds, whichever comes first
	// TODO: make timeout configurable
	timeout := 10 * time.Second
	select {
	case <-emc:
		glog.V(0).Infof("Container %s started instance %s for service %s (%s)", ctr.ID, state.Id, svc.Name, svc.Id)
	case <-time.After(timeout):
		// FIXME: WORKAROUND for issue where docker.Start event doesn't always notify
		if container, err := dc.InspectContainer(ctr.ID); err != nil {
			glog.Warningf("Container %s could not be inspected: %s", ctr.ID, err)
		} else {
			glog.Warningf("Container %s inspected for state %s", ctr.ID, container.State)
			if container.State.Running == true {
				glog.Infof("Container %s start event timed out, but is running - will not retyrn start timed out", ctr.ID)
				break
			}
		}
		return fmt.Errorf("start timed out")
	}
	go a.waitInstance(dc, done, state)
	return nil
}

// configureContainer creates and populates two structures, a docker client Config and a docker client HostConfig structure
// that are used to create and start a container respectively. The information used to populate the structures is pulled from
// the service, serviceState, and conn values that are passed into configureContainer.
func (a *HostAgent) configureContainer(client *ControlClient, done chan<- interface{}, svc *service.Service, state *servicestate.ServiceState) (*docker.Config, *docker.HostConfig, error) {
	var (
		dockerconfig docker.Config
		hostconfig   docker.HostConfig
	)

	// get this service's tenantID for volume mapping
	var tenantID string
	if err := client.GetTenantId(svc.Id, &tenantID); err != nil {
		glog.Errorf("Failed getting tenantID for service %s (%s): %s", svc.Name, svc.Id, err)
	}

	// get the system user
	var (
		unused     int
		systemuser user.User
	)
	if err := client.GetSystemUser(unused, &systemuser); err != nil {
		glog.Errorf("Unable to get system user account for agent %s", err)
	}
	glog.V(1).Infof("System User %v", systemuser)

	dockerconfig.Image = svc.ImageID

	// get the endpoints
	dockerconfig.ExposedPorts = make(map[docker.Port]struct{})
	hostconfig.PortBindings = make(map[docker.Port][]docker.PortBinding)

	if svc.Endpoints != nil {
		glog.V(1).Infof("Endpoints for service %s (%s): %v", svc.Name, svc.Id, svc.Endpoints)
		for _, endpoint := range svc.Endpoints {
			if endpoint.Purpose == "export" { // only expose remote endpoints
				var p string
				switch endpoint.Protocol {
				case commands.UDP:
					p = fmt.Sprintf("%d/%s", endpoint.PortNumber, "udp")
				default:
					p = fmt.Sprintf("%d/%s", endpoint.PortNumber, "tcp")
				}
				dockerconfig.ExposedPorts[docker.Port(p)] = struct{}{}
				bindings := hostconfig.PortBindings[docker.Port(p)]
				hostconfig.PortBindings[docker.Port(p)] = append(bindings, docker.PortBinding{})
			}
		}
	}

	if tenantID == "" && len(service.Volumes) > 0 {
		// FIXME: find a better way of handling this error condition
		glog.Fatalf("Could not get tenant ID and need to mount a volume for instance %s under service %s (%s)", state.Id, svc.Name.svc.Id)
	}

	// make sure the image exists locally
	registry, err := commons.NewDockerRegistry(a.dockerRegistry)
	if err != nil {
		glog.Errorf("Error using docker registry %s: %s", a.dockerRegistry, err)
		return nil, nil, err
	}

	dc, err := docker.NewClient(dockerEndpoint)
	if err != nil {
		glog.Errorf("Cannot create docker client: %v", err)
		return nil, nil, err
	}

	if _, err := commons.InspectImage(registry, dc, svc.ImageID); err != nil {
		glog.Errorf("Cannot inspect docker image %s: %s", svc.ImageID, err)
		return nil, nil, err
	}

	dockerconfig.Volumes = make(map[string]struct{})
	hostconfig.Binds = []string{}

	for _, volume := range service.Volumes {
		subvolume, err := getSubvolume(a.varPath, svc.PoolID, tenantID, a.vfs)
		if err != nil {
			glog.Fatalf("Could not create subvolume: %s", err)
		} else {
			glog.V(2).Infof("Volume for service %s (%s)", svc.Name, svc.Id)
			resourcePath := path.Join(subvolume.Path(), volume.ResourcePath)
			glog.V(2).Infof("FullResourcePath: %s", resourcePath)
			if err := os.MkdirAll(resourcePath, 0770); err != nil {
				glog.Fatalf("Could not create resource path %s: %s", resourcePath, err)
			}

			if err := createVolumeDir(resourcePath, volume.ContainerPath, svc.ImageID, volume.Owner, volume.Permission); err != nil {
				glog.Errorf("Error populating resource path %s with container path %s: %s", resourcePath, volume.ContainerPath, err)
			}

			binding := fmt.Sprintf("%s:%s", resourcePath, volume.ContainerPath)
			dockerconfig.Volumes[strings.Split(binding, ":")[1]] = struct{}{}
			hostconfig.Binds(hostconfig.Binds, strings.TrimSpace(binding))
		}
	}

	dir, binary, err := ExecPath()
	if err != nil {
		glog.Errorf("Error getting exec path: %s", err)
		return nil, nil, err
	}

	volumeBinding := fmt.Sprintf("%s:/serviced", dir)
	dockerconfig.Volumes[strings.Split(volumeBinding, ":")[1]] = struct{}{}
	hostconfig.Binds = append(hostconfig.Binds, strings.TrimSpace(volumeBinding))

	if err := injectContext(svc, client); err != nil {
		glog.Errorf("Error injecting context: %s", err)
		return nil, nil, err
	}

	// bind mount everything we need for logstash-forwarder
	if len(service.LogConfigs) != 0 {
		const LOGSTASH_CONTAINER_DIRECTORY = "/use/local/serviced/resources/logstash"
		logstashPath := utils.ResourcesDir() + "/logstash"
		binding := fmt.Sprintf("%s:%s", logstashPath, LOGSTASH_CONTAINER_DIRECTORY)
		dockerconfig.Volumes[LOGSTASH_CONTAINER_DIRECTORY] = struct{}{}
		hostconfig.Binds(hostconfig.Binds, binding)
		glog.V(1).Infof("Added logstash bind mount: %s", binding)
	}

	// add arguments to mount requested directory (if requested)
	glog.V(2).Infof("Checking mount options for service %s (%s)", svc.Name, svc.Id)
	for _, bindmountStr := range a.mount {
		glog.V(2).Infof("Bindmount is %s", bindmountStr)
		splitMount := strings.Split(bindmountStr, ",")

		if splitMount := strings.Split(bindmountStr, ","); len(splitMount) >= 2 {
			requestedImage, hostPath := splitMount[0], splitMount[1]
			// assume the container path is going to be the same as the host path
			containerPath := hostPath
			if len(splitMount) > 2 {
				containerPath = splitMount[2]
			}
			glog.V(2).Infof("Mount requested image: %s; host path: %s; container path: %s", requestedImage, hostPath, containerPath)

			// insert tenantID into requestedImage - see dao.DeployService
			matchedRequestedImage := requestedImage == "*"
			if !matchedRequestedImage {
				imageID, err := commons.ParseImageID(requestedImage)
				if err != nil {
					glog.Errorf("Error parsing imageID %s: %s", requestedImage, err)
					continue
				}
				svcImageID, err := commons.ParseImageID(svc.ImageID)
				if err != nil {
					glog.Errorf("Error parsint service imageID %s: %s", svc.ImageID, err)
					continue
				}
				glog.V(2).Infof("Mount checking %#v and %#v", imageID, svcImageID)
				matchedRequestedImage = (imageID.Repo == svcImageID.Repo)
			}
			if matchedRequestedImage {
				binding := fmt.Sprintf("%s:%s", hostPath, containerPath)
				dockerconfig.Volumes[strings.Split(binding, ":")[1]] = struct{}{}
				hostconfig.Binds = append(hostconfig.Binds, strings.TrimSpace(binding))
			} else {
				glog.Warningf("Could not bind mount %s", bindmountString)
			}
		}
	}

	// Get host IP
	ip, err := utils.GetIPAddress()
	if err != nil {
		glog.Errorf("Error getting host IP address: %v", err)
		return nil, nil, err
	}

	// add arguments for environment variables
	dockerconfig.Env = []string{
		fmt.Sprint("CONTROLPLANE_SYSTEM_USER=", systemUser.Name),
		fmt.Sprint("CONTROLPLANE_SYSTEM_PASSWORD=", systemUser.Password),
		fmt.Sprint("CONTROLPLANE_HOST_IP=", ip),
		fmt.Sprint("SERVICED_NOREGISTRY=", os.Getenv("SERVICED_NOREGISTRY")),
	}

	// add dns values to setup
	for _, addr := range a.dockerDNS {
		_addr := strings.TrimSpace(addr)
		if _addr != "" {
			dockerconfig.Dns = append(dockerconfig.Dns, _addr)
		}
	}

	// add hostname if set
	if svc.Hostname != "" {
		dockerconfig.Hostname = svc.Hostname
	}

	dockerconfig.Cmd = []string{
		fmt.Sprintf("/serviced/%s", binary),
		"service",
		"proxy",
		svc.Id,
		strconf.Itoa(state.InstanceID),
		svc.Startup,
	}

	if svc.Privileged {
		hostconfig.Privileged = true
	}

	return dockerconfig, hostconfig, nil
}

// main loop of the HostAgent
func (a *HostAgent) start() {
	glog.Info("Starting HostAgent")
	for {
		// create a wrapping function so that client.Close() can be handled via defer
		keepGoing := func() bool {
			connc := make(chan coordclient.Connection)
			var conn coordclient.Connection
			done := make(chan interface{})
			defer close(done)

			go func() {
				defer close(connc)
				for {
					// exit when the parent exits
					select {
					case <-time.After(time.Second):
						c, err := a.zkClient.GetConnection()
						if err != nil {
							continue
						}
						connc <- c
						return
					case <-done:
						return
					}
					c, err := a.zkClient.GetConnection()
					if err == nil {
						connc <- c
						return
					}
				}
			}()

			select {
			case errc := <-a.closing:
				glog.Info("Received shutdown notice")
				a.zkClient.Close()
				errc <- fmt.Errorf("unable to connect to zookeeper")
				return false
			case conn := <-connc:
				glog.Info("Got a connected client")
			}
			defer conn.Close()

			// Watch virtual ip zookeeper nodes
			go zkVirtualIP.NewVIPListener(conn, a).Listen()

			// Watch docker action nodes
			go zkDocker.NewActionListener(conn, a.hostId).Listen()

			// Watch host nodes
			zkDocker.NewHostListener(done, conn, a, a.hostId).Listen()
			return true
		}()
		if !keepGoing {
			break
		}
	}
}

func (agent *HostAgent) BindVirtualIP(vip *pool.VirtualIP, index int) (string, error) {
	// check if the ip exists
	if vmap, err := mapVirtualIPs(); err != nil {
		return "", err
	} else if _, ok := vmap[vip.IP]; ok {
		return "", fmt.Errorf("requested virtual ip already on this host")
	}

	viname := vip.BindInterface + viPrefix + strconv.Itoa(index)
	if err := bind(vip, viname); err != nil {
		return "", err
	}

	return utils.HostID()
}

func (agent *HostAgent) UnbindVirtualIP(vip *pool.VirtualIP) error {
	// verify the address lives on this host
	if vmap, err := mapVirtualIPs(); err != nil {
		return err
	} else if _, ok := vmap[vip.IP]; !ok {
		glog.Warningf("Virtual IP %s not found on this host", vip.IP)
		return nil
	} else if err := unbind(vip.InterfaceName); err != nil {
		return err
	}
	return nil
}

type stateResult struct {
	id  string
	err error
}

// startMissingChildren accepts a zookeeper connection (conn) and a slice of service instance ids (children),
// a map of channels to signal running children stop, and a stateResult channel for children to signal when
// they shutdown
func (a *HostAgent) startMissingChildren(conn coordclient.Connection, children []string, processing map[string]chan int, ssDone chan stateResult) {
	glog.V(1).Infof("Agent for %s processing %d children", a.hostID, len(children))
	for _, childName := range children {
		if processing[childName] == nil {
			glog.V(2).Info("Agent starting goroutine to watch ", childName)
			childChannel := make(chan int, 1)
			processing[childName] = childChannel
			go a.processServiceState(conn, childChannel, ssDone, childName)
		}
	}
	return
}

func waitForSsNodes(processing map[string]chan int, ssResultChan chan stateResult) (err error) {
	for key, shutdown := range processing {
		glog.V(1).Infof("Agent signaling for %s to shutdown.", key)
		shutdown <- 1
	}

	// Wait for goroutines to shutdown
	for len(processing) > 0 {
		select {
		case ssResult := <-ssResultChan:
			glog.V(1).Infof("Goroutine finished %s", ssResult.id)
			if err == nil && ssResult.err != nil {
				err = ssResult.err
			}
			delete(processing, ssResult.id)
		}
	}
	glog.V(0).Info("All service state nodes are shut down")
	return
}

func (a *HostAgent) processChildrenAndWait(conn coordclient.Connection) bool {
	processing := make(map[string]chan int)
	ssDone := make(chan stateResult, 25)

	hostPath := zzk.HostPath(a.hostID)

	for {

		glog.V(3).Infof("creating hostdir: %s", hostPath)
		conn.CreateDir(hostPath)

		glog.V(3).Infof("getting children of %s", hostPath)
		children, zkEvent, err := conn.ChildrenW(hostPath)
		if err != nil {
			glog.V(0).Infof("Unable to read children, retrying: %s", err)
			select {
			case <-time.After(3 * time.Second):
				return true
			case errc := <-a.closing:
				glog.V(1).Info("Agent received interrupt")
				err = waitForSsNodes(processing, ssDone)
				errc <- err
				return false
			}
		}
		a.startMissingChildren(conn, children, processing, ssDone)

		select {

		case errc := <-a.closing:
			glog.V(1).Info("Agent received interrupt")
			err = waitForSsNodes(processing, ssDone)
			errc <- err
			return false

		case ssResult := <-ssDone:
			glog.V(1).Infof("Goroutine finished %s", ssResult.id)
			delete(processing, ssResult.id)

		case evt := <-zkEvent:
			glog.V(1).Info("Agent event: ", evt)
		}
	}
}

func (a *HostAgent) processServiceState(conn coordclient.Connection, shutdown <-chan int, done chan<- stateResult, ssID string) {
	procFinished := make(chan int, 1)
	var attached bool

	for {
		var hss zzk.HostServiceState
		zkEvent, err := zzk.LoadHostServiceStateW(conn, a.hostID, ssID, &hss)
		if err != nil {
			errS := fmt.Sprintf("Unable to load host service state %s: %v", ssID, err)
			glog.Error(errS)
			done <- stateResult{ssID, errors.New(errS)}
			return
		}
		if len(hss.ServiceStateID) == 0 || len(hss.ServiceID) == 0 {
			errS := fmt.Sprintf("Service for %s is invalid", zzk.HostServiceStatePath(a.hostID, ssID))
			glog.Error(errS)
			done <- stateResult{ssID, errors.New(errS)}
			return
		}

		var ss servicestate.ServiceState
		if err := zzk.LoadServiceState(conn, hss.ServiceID, hss.ServiceStateID, &ss); err != nil {
			errS := fmt.Sprintf("Host service state unable to load service state %s", ssID)
			glog.Error(errS)
			// This goroutine is watching a node for a service state that does not
			// exist or could not be loaded. We should *probably* delete this node.
			hssPath := zzk.HostServiceStatePath(a.hostID, ssID)
			if err := conn.Delete(hssPath); err != nil {
				glog.Warningf("Unable to delete host service state %s", hssPath)
			}
			done <- stateResult{ssID, errors.New(errS)}
			return
		}

		var svc service.Service
		if err := zzk.LoadService(conn, ss.ServiceID, &svc); err != nil {
			errS := fmt.Sprintf("Host service state unable to load service %s", ss.ServiceID)
			glog.Errorf(errS)
			done <- stateResult{ssID, errors.New(errS)}
			return
		}

		glog.V(1).Infof("Processing %s, desired state: %d", svc.Name, hss.DesiredState)

		switch {

		case hss.DesiredState == service.SVCStop:
			// This node is marked for death
			glog.V(1).Infof("Service %s was marked for death, quitting", svc.Name)
			if attached {
				err = a.terminateAttached(conn, procFinished, &ss)
			} else {
				err = a.terminateInstance(conn, &ss)
			}
			done <- stateResult{ssID, err}
			return

		case attached:
			// Something uninteresting happened. Why are we here?
			glog.V(1).Infof("Service %s is attached in a child goroutine", svc.Name)

		case hss.DesiredState == service.SVCRun &&
			ss.Started.Year() <= 1 || ss.Terminated.Year() > 2:
			// Should run, and either not started or process died
			glog.V(1).Infof("Service %s does not appear to be running; starting", svc.Name)
			attached, err = a.startService(conn, procFinished, &svc, &ss)

		case ss.Started.Year() > 1 && ss.Terminated.Year() <= 1:
			// Service superficially seems to be running. We need to attach
			glog.V(1).Infof("Service %s appears to be running; attaching", svc.Name)
			attached, err = a.attachToService(conn, procFinished, &ss, &hss)

		default:
			glog.V(0).Infof("Unhandled service %s", svc.Name)
		}

		if !attached || err != nil {
			errS := fmt.Sprintf("Service state %s unable to start or attach to process", ssID)
			glog.V(1).Info(errS)
			a.terminateInstance(conn, &ss)
			done <- stateResult{ssID, errors.New(errS)}
			return
		}

		glog.V(3).Infoln("Successfully processed state for %s", svc.Name)

		select {

		case <-shutdown:
			glog.V(0).Info("Agent goroutine will stop watching ", ssID)
			err = a.terminateAttached(conn, procFinished, &ss)
			if err != nil {
				glog.Errorf("Error terminating %s: %v", svc.Name, err)
			}
			done <- stateResult{ssID, err}
			return

		case <-procFinished:
			glog.V(1).Infof("Process finished %s", ssID)
			attached = false
			continue

		case evt := <-zkEvent:
			if evt.Type == coordclient.EventNodeDeleted {
				glog.V(0).Info("Host service state deleted: ", ssID)
				err = a.terminateAttached(conn, procFinished, &ss)
				if err != nil {
					glog.Errorf("Error terminating %s: %v", svc.Name, err)
				}
				done <- stateResult{ssID, err}
				return
			}

			glog.V(1).Infof("Host service state %s received event %v", ssID, evt)
			continue
		}
	}
}
